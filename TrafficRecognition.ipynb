{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import keras\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout,Activation\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "cur_path = r'E:\\Imarticus Learning\\PGA14_Deep Learning\\Traffic Recognition using CV & DeepLearning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "classes = 43\n",
    " \n",
    "#Retrieving the images and their labels \n",
    "for i in range(classes):\n",
    "    path = os.path.join(cur_path,'train',str(i))\n",
    "    images = os.listdir(path)\n",
    "\n",
    "    for a in images:\n",
    "        try:\n",
    "            image = Image.open(path + '\\\\'+ a)\n",
    "            image = image.resize((30,30))\n",
    "            image = np.array(image)\n",
    "    \n",
    "            #data.append(image)\n",
    "            #labels.append(i)\n",
    "            data.append([image,i]) #appending all value together \n",
    "        except:\n",
    "            print(\"Error loading image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39209\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for features,label in data:\n",
    "    x.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting lists into numpy arrays\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "X_val = X_val/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train images is: (31367, 30, 30, 3)\n",
      "Shape of labels is: (31367,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train images is:\", X_train.shape)\n",
    "print(\"Shape of labels is:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(30, 30, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(43))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "981/981 [==============================] - 48s 45ms/step - loss: 2.5036 - accuracy: 0.2801 - val_loss: 1.3429 - val_accuracy: 0.5282\n",
      "Epoch 2/20\n",
      "981/981 [==============================] - 45s 45ms/step - loss: 1.3458 - accuracy: 0.5487 - val_loss: 0.6452 - val_accuracy: 0.7892\n",
      "Epoch 3/20\n",
      "981/981 [==============================] - 40s 41ms/step - loss: 0.8524 - accuracy: 0.7113 - val_loss: 0.3568 - val_accuracy: 0.8846\n",
      "Epoch 4/20\n",
      "981/981 [==============================] - 37s 38ms/step - loss: 0.5872 - accuracy: 0.8031 - val_loss: 0.1818 - val_accuracy: 0.9445\n",
      "Epoch 5/20\n",
      "981/981 [==============================] - 57s 58ms/step - loss: 0.4274 - accuracy: 0.8566 - val_loss: 0.1052 - val_accuracy: 0.9713\n",
      "Epoch 6/20\n",
      "981/981 [==============================] - 45s 46ms/step - loss: 0.3228 - accuracy: 0.8928 - val_loss: 0.0846 - val_accuracy: 0.9762\n",
      "Epoch 7/20\n",
      "981/981 [==============================] - 42s 43ms/step - loss: 0.2615 - accuracy: 0.9148 - val_loss: 0.0553 - val_accuracy: 0.9858\n",
      "Epoch 8/20\n",
      "981/981 [==============================] - 40s 41ms/step - loss: 0.2159 - accuracy: 0.9297 - val_loss: 0.0367 - val_accuracy: 0.9890\n",
      "Epoch 9/20\n",
      "981/981 [==============================] - 38s 38ms/step - loss: 0.1828 - accuracy: 0.9420 - val_loss: 0.0391 - val_accuracy: 0.9887\n",
      "Epoch 10/20\n",
      "981/981 [==============================] - 37s 38ms/step - loss: 0.1552 - accuracy: 0.9511 - val_loss: 0.0287 - val_accuracy: 0.9918\n",
      "Epoch 11/20\n",
      "981/981 [==============================] - 37s 38ms/step - loss: 0.1336 - accuracy: 0.9584 - val_loss: 0.0354 - val_accuracy: 0.9897\n",
      "Epoch 12/20\n",
      "981/981 [==============================] - 38s 39ms/step - loss: 0.1238 - accuracy: 0.9610 - val_loss: 0.0238 - val_accuracy: 0.9925\n",
      "Epoch 13/20\n",
      "981/981 [==============================] - 37s 38ms/step - loss: 0.1044 - accuracy: 0.9674 - val_loss: 0.0200 - val_accuracy: 0.9943\n",
      "Epoch 14/20\n",
      "981/981 [==============================] - 40s 41ms/step - loss: 0.0996 - accuracy: 0.9692 - val_loss: 0.0140 - val_accuracy: 0.9955\n",
      "Epoch 15/20\n",
      "981/981 [==============================] - 41s 42ms/step - loss: 0.0984 - accuracy: 0.9696 - val_loss: 0.0107 - val_accuracy: 0.9967\n",
      "Epoch 16/20\n",
      "981/981 [==============================] - 41s 42ms/step - loss: 0.0862 - accuracy: 0.9736 - val_loss: 0.0150 - val_accuracy: 0.9959\n",
      "Epoch 17/20\n",
      "981/981 [==============================] - 41s 41ms/step - loss: 0.0792 - accuracy: 0.9761 - val_loss: 0.0152 - val_accuracy: 0.9955\n",
      "Epoch 18/20\n",
      "981/981 [==============================] - 38s 39ms/step - loss: 0.0827 - accuracy: 0.9756 - val_loss: 0.0127 - val_accuracy: 0.9964\n",
      "Epoch 19/20\n",
      "981/981 [==============================] - 40s 40ms/step - loss: 0.0688 - accuracy: 0.9794 - val_loss: 0.0162 - val_accuracy: 0.9953\n",
      "Epoch 20/20\n",
      "981/981 [==============================] - 40s 40ms/step - loss: 0.0715 - accuracy: 0.9788 - val_loss: 0.0154 - val_accuracy: 0.9953\n"
     ]
    }
   ],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "model.fit(aug.flow(X_train, y_train, batch_size=32), epochs=20, validation_data=(X_val, y_val))\n",
    "\n",
    "model.save('my_model.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing accuracy on test dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test = pd.read_csv('Test.csv')\n",
    "\n",
    "labels = y_test[\"ClassId\"].values\n",
    "imgs = y_test[\"Path\"].values\n",
    "\n",
    "data=[]\n",
    "\n",
    "for img in imgs:\n",
    "    image = Image.open(img)\n",
    "    image = image.resize((30,30))\n",
    "    data.append(np.array(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[116, 140, 175],\n",
       "        [116, 138, 171],\n",
       "        [119, 138, 173],\n",
       "        ...,\n",
       "        [102, 119, 150],\n",
       "        [101, 122, 149],\n",
       "        [ 93, 112, 139]],\n",
       "\n",
       "       [[116, 142, 177],\n",
       "        [116, 141, 175],\n",
       "        [117, 141, 174],\n",
       "        ...,\n",
       "        [120, 143, 178],\n",
       "        [122, 144, 176],\n",
       "        [122, 142, 174]],\n",
       "\n",
       "       [[118, 142, 174],\n",
       "        [116, 141, 175],\n",
       "        [114, 140, 172],\n",
       "        ...,\n",
       "        [121, 144, 181],\n",
       "        [122, 144, 180],\n",
       "        [119, 142, 178]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[117, 137, 168],\n",
       "        [115, 135, 165],\n",
       "        [116, 135, 164],\n",
       "        ...,\n",
       "        [116, 138, 170],\n",
       "        [116, 136, 168],\n",
       "        [118, 139, 171]],\n",
       "\n",
       "       [[116, 136, 166],\n",
       "        [115, 134, 167],\n",
       "        [115, 133, 165],\n",
       "        ...,\n",
       "        [114, 135, 168],\n",
       "        [116, 136, 166],\n",
       "        [115, 139, 167]],\n",
       "\n",
       "       [[112, 135, 166],\n",
       "        [111, 134, 165],\n",
       "        [119, 135, 166],\n",
       "        ...,\n",
       "        [115, 137, 166],\n",
       "        [117, 138, 167],\n",
       "        [114, 140, 170]]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 6s 11ms/step\n",
      "0.9096595407759304\n"
     ]
    }
   ],
   "source": [
    "X_test=np.array(data)\n",
    "\n",
    "#pred = model.predict_classes(X_test)  \n",
    "\n",
    "pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "#Accuracy with the test data\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(labels, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we are testing our model on our saved model also we can test on our 15 epoch data result we got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'Test\\00015.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "No passing\n"
     ]
    }
   ],
   "source": [
    "#from keras.preprocessing import image\n",
    "img = image.load_img(path, target_size = (30,30)) #load the image\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "value = classes = np.argmax(model.predict(images,batch_size=32),axis=-1) #predict the label for the image\n",
    "\n",
    "if classes[0]==0:\n",
    "    print('Speed limit (20km/h)') #print the content\n",
    "\n",
    "elif classes[0]==1:\n",
    "        print('Speed limit (30km/h)') #print the content\n",
    "\n",
    "elif classes[0]==2:\n",
    "        print('Speed limit (50km/h)') #print the content\n",
    "\n",
    "elif classes[0]==3:\n",
    "        print(' Speed limit (60km/h)') #print the content\n",
    "\n",
    "elif classes[0]==4:\n",
    "        print('Speed limit (70km/h)') #print the content\n",
    "\n",
    "elif classes[0]==5:\n",
    "        print('Speed limit (80km/h)') #print the content\n",
    "\n",
    "elif classes[0]==6:\n",
    "        print('End of speed limit (80km/h)') #print the content\n",
    "\n",
    "elif classes[0]==7:\n",
    "        print('Speed limit (100km/h)') #print the content\n",
    "\n",
    "elif classes[0]==8:\n",
    "        print('Speed limit (120km/h)') #print the content\n",
    "\n",
    "elif classes[0]==9:\n",
    "        print('No passing') #print the content\n",
    "        \n",
    "elif classes[0]==10:\n",
    "        print('No passing veh over 3.5 tons') #print the content \n",
    "    \n",
    "elif classes[0]==11:\n",
    "        print(', Right-of-way at intersection') #print the content\n",
    "        \n",
    "elif classes[0]==12:\n",
    "        print('Priority road') #print the content\n",
    "        \n",
    "elif classes[0]==13:\n",
    "        print('Yield') #print the content       \n",
    "        \n",
    "elif classes[0]==14:\n",
    "        print('Stop') #print the content       \n",
    "        \n",
    "elif classes[0]==15:\n",
    "        print('No vehicles') #print the content\n",
    "                \n",
    "elif classes[0]==17:\n",
    "        print('No entry') #print the content        \n",
    "                       \n",
    "elif classes[0]==18:\n",
    "        print('General caution') #print the content       \n",
    "                \n",
    "elif classes[0]==19:\n",
    "        print('Dangerous curve left') #print the content        \n",
    "        \n",
    "elif classes[0]==20:\n",
    "        print('Dangerous curve right') #print the content        \n",
    "        \n",
    "elif classes[0]==21:\n",
    "        print('Double curve') #print the content       \n",
    "        \n",
    "elif classes[0]==23:\n",
    "        print('Slippery road') #print the content        \n",
    "        \n",
    "elif classes[0]==24:\n",
    "        print('Road narrows on the right') #print the content\n",
    "        \n",
    "elif classes[0]==24:\n",
    "        print('Road narrows on the right') #print the content               \n",
    "        \n",
    "elif classes[0]==25:\n",
    "        print('Road work') #print the content        \n",
    "        \n",
    "elif classes[0]==26:\n",
    "        print('Traffic signals') #print the content\n",
    "        \n",
    "elif classes[0]==27:\n",
    "        print('Pedestrians') #print the content       \n",
    "                \n",
    "elif classes[0]==28:\n",
    "        print('Children crossing') #print the content\n",
    "        \n",
    "elif classes[0]==29:\n",
    "        print( 'Bicycles crossing') #print the content\n",
    "               \n",
    "elif classes[0]==30:\n",
    "        print('Beware of ice/snow') #print the content        \n",
    "        \n",
    "elif classes[0]==31:\n",
    "        print('Wild animals crossing') #print the content        \n",
    "               \n",
    "elif classes[0]==32:\n",
    "        print('End speed + passing limits') #print the content        \n",
    "        \n",
    "elif classes[0]==33:\n",
    "        print('Turn right ahead') #print the content\n",
    "        \n",
    "elif classes[0]==34:\n",
    "        print('Turn left ahead') #print the content        \n",
    "        \n",
    "elif classes[0]==35:\n",
    "        print('Ahead only') #print the content        \n",
    "               \n",
    "elif classes[0]==37:\n",
    "        print('Go straight or left') #print the content        \n",
    "        \n",
    "elif classes[0]==38:\n",
    "        print('Keep right') #print the content\n",
    "        \n",
    "elif classes[0]==39:\n",
    "        print('Keep left') #print the content       \n",
    "        \n",
    "elif classes[0]==40:\n",
    "        print('Roundabout mandatory') #print the content\n",
    "\n",
    "elif classes[0]==41:\n",
    "        print('End of no passing') #print the content        \n",
    "        \n",
    "else:\n",
    "    print('End no passing veh > 3.5 tons') #print the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TrafficCV",
   "language": "python",
   "name": "trafficcv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
